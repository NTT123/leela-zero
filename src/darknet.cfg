[net]
# Training
# batch=128
# subdivisions=8

# Testing
batch=1
height=19
width=19
channels=18
momentum=0.9
decay=0.0005

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=linear

[shortcut]
from=-3
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=linear

[shortcut]
from=-3
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=linear

[shortcut]
from=-3
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=linear

[shortcut]
from=-3
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=linear

[shortcut]
from=-3
activation=relu

[convolutional]
batch_normalize=1
filters=2
size=1
stride=1
pad=0
activation=relu

[connected]
output=362
activation=linear

[route]
layers=-3

[convolutional]
batch_normalize=1
filters=1
size=1
stride=1
pad=0
activation=relu

[connected]
output=256
activation=relu

[connected]
output=1
activation=tanh

[route]
layers=-5,-1
